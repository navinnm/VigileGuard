name: VigileGuard CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]

permissions:
  contents: read
  security-events: write
  actions: read

env:
  PYTHON_VERSION: '3.8'

jobs:
  # Code Quality Checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install black flake8 mypy bandit safety

      - name: Code formatting check
        run: |
          black --check --line-length=100 vigileguard.py
          echo "âœ… Code formatting check passed"

      - name: Lint with flake8
        run: |
          flake8 vigileguard.py --max-line-length=100 --ignore=E203,W503 --statistics
          echo "âœ… Linting check passed"

      - name: Type checking with mypy
        run: |
          mypy vigileguard.py --ignore-missing-imports
          echo "âœ… Type checking passed"
        continue-on-error: true

      - name: Security scan with bandit
        run: |
          bandit -r . -f json -o bandit-report.json || true
          echo "âœ… Security scan completed"

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: bandit-report.json
          retention-days: 30

  # Functional Testing (Fixed for VigileGuard behavior)
  test:
    name: Test Python ${{ matrix.python-version }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, ubuntu-20.04]
        python-version: ["3.8", "3.9", "3.10", "3.11"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Test VigileGuard basic functionality
        run: |
          echo "ğŸ§ª Testing basic commands..."
          python vigileguard.py --help
          python vigileguard.py --version
          echo "âœ… Basic functionality tests passed"

      - name: Test JSON output
        run: |
          echo "ğŸ§ª Testing JSON output generation..."
          python vigileguard.py --format json --output test-report.json || true
          
          if [ -f test-report.json ]; then
            echo "âœ… JSON file created successfully"
            python -c "
          import json
          with open('test-report.json', 'r') as f:
              data = json.load(f)
              assert 'scan_info' in data, 'Missing scan_info'
              assert 'summary' in data, 'Missing summary'
              assert 'findings' in data, 'Missing findings'
              print('âœ… JSON structure is valid')
          "
            python -c "
          import json
          with open('test-report.json', 'r') as f:
              data = json.load(f)
              total = data['summary']['total_findings']
              print(f'ğŸ“Š Found {total} total findings')
              for severity, count in data['summary']['by_severity'].items():
                  print(f'  {severity}: {count}')
          "
            echo "âœ… JSON output test completed successfully"
          else
            echo "âŒ JSON file was not created"
            exit 1
          fi

      - name: Test with custom config
        run: |
          echo "ğŸ§ª Testing custom configuration..."
          python vigileguard.py --config config.yaml --format json --output config-test.json || true
          
          if [ -f config-test.json ]; then
            echo "âœ… Custom config test passed"
          else
            echo "âŒ Config test failed"
            exit 1
          fi

      - name: Test error handling
        run: |
          echo "ğŸ§ª Testing error handling..."
          echo "invalid: yaml: content" > invalid-config.yaml
          python vigileguard.py --config invalid-config.yaml --format json || true
          echo "âœ… Error handling test completed"

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.python-version }}-${{ matrix.os }}
          path: |
            test-report.json
            config-test.json
          retention-days: 30

  # Docker Testing
  docker:
    name: Docker Build & Test
    runs-on: ubuntu-latest
    needs: [quality]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        run: |
          docker build -t vigileguard:test .
          echo "âœ… Docker image built successfully"

      - name: Test Docker image functionality
        run: |
          echo "ğŸ³ Testing Docker image..."
          docker run --rm vigileguard:test --help
          docker run --rm vigileguard:test --version
          docker run --rm vigileguard:test --format json > docker-test-report.json || true
          
          if [ -f docker-test-report.json ] && [ -s docker-test-report.json ]; then
            echo "âœ… Docker JSON output test passed"
          else
            echo "âŒ Docker JSON output test failed"
            exit 1
          fi

      - name: Upload Docker test results
        uses: actions/upload-artifact@v4
        with:
          name: docker-test-results
          path: docker-test-report.json
          retention-days: 30

  # Installation Script Testing
  install-test:
    name: Installation Script Test
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Test install script syntax
        run: |
          chmod +x install.sh
          bash -n install.sh
          echo "âœ… Install script syntax check passed"

      - name: Test install script help
        run: |
          ./install.sh --help
          ./install.sh --version
          echo "âœ… Install script help test passed"

  # Security Testing (Separate from functional tests)
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # VigileGuard Demo
  demo:
    name: VigileGuard Security Demo
    runs-on: ubuntu-latest
    needs: [test]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run VigileGuard Demo
        run: |
          echo "ğŸ›¡ï¸ VigileGuard Security Audit Demo"
          echo "=================================="
          echo ""
          echo "Running security audit on GitHub Actions runner..."
          echo ""
          
          python vigileguard.py --format console || true
          
          echo ""
          echo "ğŸ“Š Generating detailed JSON report..."
          python vigileguard.py --format json --output demo-report.json || true
          
          if [ -f demo-report.json ]; then
            echo ""
            echo "ğŸ“‹ Security Audit Summary:"
            python -c "
          import json
          with open('demo-report.json', 'r') as f:
              data = json.load(f)
              print(f'ğŸ” Total findings: {data[\"summary\"][\"total_findings\"]}')
              for severity, count in data['summary']['by_severity'].items():
                  if count > 0:
                      emoji = 'ğŸ”´' if severity in ['CRITICAL', 'HIGH'] else 'ğŸŸ¡' if severity == 'MEDIUM' else 'ğŸ”µ'
                      print(f'{emoji} {severity}: {count}')
              print('')
              print('âœ… VigileGuard successfully identified security issues!')
              print('ğŸ“– This demonstrates the tool is working correctly.')
          "
          fi

      - name: Upload demo results
        uses: actions/upload-artifact@v4
        with:
          name: vigileguard-demo
          path: demo-report.json
          retention-days: 30

  # Final Status
  status:
    name: Build Status
    runs-on: ubuntu-latest
    needs: [quality, test, docker, install-test]
    if: always()
    
    steps:
      - name: Check overall status
        run: |
          echo "ğŸ›¡ï¸ VigileGuard CI/CD Pipeline Status"
          echo "===================================="
          
          if [[ "${{ needs.quality.result }}" == "success" && "${{ needs.test.result }}" == "success" && "${{ needs.docker.result }}" == "success" && "${{ needs.install-test.result }}" == "success" ]]; then
            echo "âœ… All tests passed!"
            echo "ğŸ‰ VigileGuard is ready for deployment"
            exit 0
          else
            echo "âŒ Some tests failed:"
            echo "  Quality: ${{ needs.quality.result }}"
            echo "  Test: ${{ needs.test.result }}"
            echo "  Docker: ${{ needs.docker.result }}"
            echo "  Install: ${{ needs.install-test.result }}"
            exit 1
          fi